{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11906154,"sourceType":"datasetVersion","datasetId":7484531}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import MultiStepLR\nfrom tqdm import tqdm\nimport copy\n\n# âœ… GPU ì„¤ì •\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n\n# âœ… ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\ndf_train = pd.read_csv(\"/kaggle/input/poiuyt/train.csv\")  # ê²½ë¡œ ì¡°ì • í•„ìš”\n\n# âœ… label 0ê³¼ 1ì—ì„œ ê°ê° 250ê°œì”© ìƒ˜í”Œë§\nsampled_0 = df_train[df_train['label'] == 0].sample(n=250, random_state=42)\nsampled_1 = df_train[df_train['label'] == 1].sample(n=250, random_state=42)\ndf_sampled = pd.concat([sampled_0, sampled_1]).reset_index(drop=True)\n\n# âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„°\nMAX_LEN = 512\nBATCH_SIZE = 32\nEPOCHS = 30\nNUM_FOLDS = 5\n\n# âœ… í† í¬ë‚˜ì´ì €\ntokenizer = BertTokenizer.from_pretrained(\"klue/bert-base\")\n\n# âœ… Dataset í´ë˜ìŠ¤\nclass TextDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        encoding = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding='max_length',\n            max_length=self.max_len,\n            return_tensors='pt'\n        )\n        return {\n            'input_ids': encoding['input_ids'].squeeze(0),\n            'attention_mask': encoding['attention_mask'].squeeze(0),\n            'label': torch.tensor(self.labels[idx], dtype=torch.float)\n        }\n\n# âœ… ëª¨ë¸ ì •ì˜ (LSTM + BERT)\nclass LSTMClassifier(nn.Module):\n    def __init__(self, hidden_dim=256, num_layers=1, freeze_bert=True):\n        super(LSTMClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(\"klue/bert-base\")\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n        self.lstm = nn.LSTM(input_size=768, hidden_size=hidden_dim, num_layers=num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        lstm_out, _ = self.lstm(outputs.last_hidden_state)\n        final_hidden = lstm_out[:, -1, :]\n        logits = self.fc(final_hidden)\n        return self.sigmoid(logits).squeeze()\n\n# âœ… í‰ê°€ í•¨ìˆ˜\ndef evaluate(model, loader, criterion):\n    model.eval()\n    total_loss = 0\n    preds, labels_all = [], []\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            preds += (outputs > 0.5).cpu().tolist()\n            labels_all += labels.cpu().tolist()\n    return total_loss / len(loader), accuracy_score(labels_all, preds)\n\n# âœ… Stratified K-Fold í›ˆë ¨\nskf = StratifiedKFold(n_splits=NUM_FOLDS, shuffle=True, random_state=42)\nfold_results = []\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(df_sampled['text'], df_sampled['label'])):\n    print(f\"\\nğŸ” Fold {fold + 1}/{NUM_FOLDS}\")\n\n    train_df = df_sampled.iloc[train_idx]\n    val_df = df_sampled.iloc[val_idx]\n\n    train_dataset = TextDataset(train_df['text'].tolist(), train_df['label'].tolist(), tokenizer, MAX_LEN)\n    val_dataset = TextDataset(val_df['text'].tolist(), val_df['label'].tolist(), tokenizer, MAX_LEN)\n    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n\n    model = LSTMClassifier(freeze_bert=False).to(device)\n    criterion = nn.BCELoss()\n    optimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=2e-5, weight_decay=0.01)\n    scheduler = MultiStepLR(optimizer, milestones=[10, 20], gamma=0.5)\n\n    best_val_acc = 0\n    early_stop_counter = 0\n    early_stop_patience = 3\n\n    for epoch in range(EPOCHS):\n        model.train()\n        total_loss, correct, total = 0, 0, 0\n        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} (Fold {fold+1})\")\n\n        for batch in loop:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(input_ids, attention_mask)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            preds = (outputs > 0.5).float()\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            loop.set_postfix(loss=loss.item())\n\n        train_acc = correct / total\n        val_loss, val_acc = evaluate(model, val_loader, criterion)\n        scheduler.step()\n\n        print(f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            early_stop_counter = 0\n            torch.save(model.state_dict(), f\"best_model_fold_{fold+1}.pt\")\n            print(\"âœ… Best model saved.\")\n        else:\n            early_stop_counter += 1\n            if early_stop_counter >= early_stop_patience:\n                print(\"ğŸ›‘ Early stopping\")\n                break\n\n    fold_results.append({'fold': fold + 1, 'val_acc': best_val_acc})\n\n# âœ… ê²°ê³¼ ì¶œë ¥\nresults_df = pd.DataFrame(fold_results)\nprint(\"\\nğŸ“Š Fold ê²°ê³¼:\\n\", results_df)\nprint(\"ğŸ“ˆ í‰ê·  ì •í™•ë„:\", results_df['val_acc'].mean())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-23T08:37:00.942186Z","iopub.execute_input":"2025-05-23T08:37:00.942348Z","iopub.status.idle":"2025-05-23T09:11:44.442335Z","shell.execute_reply.started":"2025-05-23T08:37:00.942333Z","shell.execute_reply":"2025-05-23T09:11:44.441658Z"}},"outputs":[{"name":"stderr","text":"2025-05-23 08:37:15.722281: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747989435.907975      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747989435.962091      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aeb3a78724164f9e99f7c94e39ea77da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be60cb17ce7c4b0ead1479817a537fa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84e1478e9966481594ae3809c1d9f70f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f016cb7bb94e2798c1ac152ab214cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18f6a5af50114ce0992a55907fdd3129"}},"metadata":{}},{"name":"stdout","text":"\nğŸ” Fold 1/5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e637c515ea0448f1bc81c67fb727911a"}},"metadata":{}},{"name":"stderr","text":"Epoch 1/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:41<00:00,  3.16s/it, loss=0.616]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5775 | Val Acc: 0.5600\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.41s/it, loss=0.598]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.7225 | Val Acc: 0.8000\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.39s/it, loss=0.397]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9050 | Val Acc: 0.9300\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.45s/it, loss=0.0832]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9650 | Val Acc: 0.7800\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0367]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9800 | Val Acc: 0.9900\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0439]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9900 | Val Acc: 0.9100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0188]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30 (Fold 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0156]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9300\nğŸ›‘ Early stopping\n\nğŸ” Fold 2/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.689]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6125 | Val Acc: 0.7200\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.513]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.8575 | Val Acc: 0.8600\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.42s/it, loss=0.139]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9250 | Val Acc: 0.9700\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.107] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9950 | Val Acc: 0.9600\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.45s/it, loss=0.154] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9900 | Val Acc: 0.9800\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0209]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9600\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0166]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9900\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0151]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9600\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0106]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10/30 (Fold 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.00964]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9900\nğŸ›‘ Early stopping\n\nğŸ” Fold 3/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.657]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5550 | Val Acc: 0.6200\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.581]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.7200 | Val Acc: 0.8900\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.316]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9100 | Val Acc: 0.8500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.105] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9875 | Val Acc: 0.9800\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.033] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9700\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0212]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 (Fold 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.016] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9700\nğŸ›‘ Early stopping\n\nğŸ” Fold 4/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.42s/it, loss=0.645]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5975 | Val Acc: 0.6100\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.58] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.7200 | Val Acc: 0.7700\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.289]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9350 | Val Acc: 0.9600\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.089] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9900 | Val Acc: 0.9500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0522]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9975 | Val Acc: 0.9100\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0236]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 1.0000\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0233]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9300\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0149]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 1.0000\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9/30 (Fold 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0165]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.8800\nğŸ›‘ Early stopping\n\nğŸ” Fold 5/5\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.616]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.5150 | Val Acc: 0.5600\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.623]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.6850 | Val Acc: 0.7000\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.42s/it, loss=0.408]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.8675 | Val Acc: 0.8800\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0804]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9550 | Val Acc: 0.9600\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0324]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9900\nâœ… Best model saved.\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.133] \n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9975 | Val Acc: 0.9900\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.44s/it, loss=0.0217]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 0.9975 | Val Acc: 0.9500\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8/30 (Fold 5): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13/13 [00:44<00:00,  3.43s/it, loss=0.0112]\n","output_type":"stream"},{"name":"stdout","text":"Train Acc: 1.0000 | Val Acc: 0.9700\nğŸ›‘ Early stopping\n\nğŸ“Š Fold ê²°ê³¼:\n    fold  val_acc\n0     1     0.99\n1     2     0.99\n2     3     0.98\n3     4     1.00\n4     5     0.99\nğŸ“ˆ í‰ê·  ì •í™•ë„: 0.99\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\ndf_test = pd.read_csv(\"/kaggle/input/poiuyt/test.csv\")  # ê²½ë¡œ í™•ì¸ í•„ìš”\ntest_dataset = TextDataset(\n    texts=df_test['text'].tolist(),\n    labels=[0]*len(df_test),  # ë”ë¯¸ ë¼ë²¨\n    tokenizer=tokenizer,\n    max_len=MAX_LEN\n)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n\n# âœ… ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•´ë‘” ê²½ìš° ë¶ˆëŸ¬ì˜¤ê¸° ì˜ˆì‹œ\nfold_model_paths = [f\"best_model_fold_{i}.pt\" for i in range(5)]\n\n# âœ… 5ê°œ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\nall_probs = []\n\nfor fold in range(5):\n    print(f\"ğŸ” Fold {fold+1} ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡\")\n    model = LSTMClassifier(freeze_bert=False).to(device)\n    \n    # í›ˆë ¨ ë‹¹ì‹œ ì €ì¥ëœ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n    model.load_state_dict(torch.load(f\"best_model_fold_{fold+1}.pt\", map_location=device))  # ì €ì¥ ê²½ë¡œ í™•ì¸\n    model.eval()\n    \n    probs = []\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            outputs = model(input_ids, attention_mask)\n            probs.extend(outputs.cpu().numpy())\n\n    all_probs.append(np.array(probs))\n\n# âœ… ì†Œí”„íŠ¸ë³´íŒ…: í‰ê·  í™•ë¥  â†’ 0.5 ê¸°ì¤€ ì˜ˆì¸¡\navg_probs = np.mean(all_probs, axis=0)\nfinal_preds = (avg_probs > 0.5).astype(int)\n\n# âœ… ê²°ê³¼ ì €ì¥\ndf_submission = df_test.copy()\ndf_submission['soft_voted_label'] = final_preds\ndf_submission.to_csv(\"submission_soft_voting.csv\", index=False)\nprint(\"âœ… submission_soft_voting.csv ì €ì¥ ì™„ë£Œ!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:11:44.443616Z","iopub.execute_input":"2025-05-23T09:11:44.443895Z","iopub.status.idle":"2025-05-23T09:13:23.927865Z","shell.execute_reply.started":"2025-05-23T09:11:44.443863Z","shell.execute_reply":"2025-05-23T09:13:23.927185Z"}},"outputs":[{"name":"stdout","text":"ğŸ” Fold 1 ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡\nğŸ” Fold 2 ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡\nğŸ” Fold 3 ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡\nğŸ” Fold 4 ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡\nğŸ” Fold 5 ëª¨ë¸ ë¡œë”© ë° ì˜ˆì¸¡\nâœ… submission_soft_voting.csv ì €ì¥ ì™„ë£Œ!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# âœ… ì†Œí”„íŠ¸ë³´íŒ…: í‰ê·  í™•ë¥  â†’ 0.5 ê¸°ì¤€ ì˜ˆì¸¡\navg_probs = np.mean(all_probs, axis=0)\nfinal_preds = (avg_probs > 0.5).astype(int)\n\n# âœ… ê²°ê³¼ ì €ì¥ (id, label í˜•ì‹)\ndf_submission = pd.DataFrame({\n    'id': df_test['id'],\n    'label': final_preds\n})\ndf_submission.to_csv(\"submission.csv\", index=False)\nprint(\"âœ… submission.csv ì €ì¥ ì™„ë£Œ!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-23T09:17:12.879743Z","iopub.execute_input":"2025-05-23T09:17:12.880277Z","iopub.status.idle":"2025-05-23T09:17:12.886939Z","shell.execute_reply.started":"2025-05-23T09:17:12.880253Z","shell.execute_reply":"2025-05-23T09:17:12.886306Z"}},"outputs":[{"name":"stdout","text":"âœ… submission.csv ì €ì¥ ì™„ë£Œ!\n","output_type":"stream"}],"execution_count":3}]}